{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from bnlp import BasicTokenizer\n",
    "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
    "from bnlp.corpus.util import remove_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bengali hate speech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                        sentence without punctuation  \n",
       "0                          যত্তসব পাপন শালার ফাজলামী  \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার  \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...  \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়  \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "def remove_punctuation_from_sentence(sentence):\n",
    "    sentence_without_punctuation=\"\".join([c for c in sentence if c not in string.punctuation])\n",
    "    return sentence_without_punctuation\n",
    "\n",
    "df['sentence without punctuation'] = df['sentence'].apply(lambda x:remove_punctuation_from_sentence(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "      <th>Removed Stopped word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, পাঠার, মত, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডায়, খ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                        sentence without punctuation  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                Removed Stopped word  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1                  [পাপন, শালা, রে, রিমান্ডে, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3                     [শালা, লুচ্চা, পাঠার, মত, যায়]  \n",
       "4  [তুই, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডায়, খ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Removed Stopped word'] = df['sentence without punctuation'].apply(lambda x: remove_stopwords(x,stopwords))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hate_speech']=df['Removed Stopped word'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['hate_speech'])\n",
    "sequences = tokenizer.texts_to_sequences(df['hate_speech'])\n",
    "x= pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=100))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "750/750 [==============================] - 52s 67ms/step - loss: 0.3894 - accuracy: 0.8307 - val_loss: 0.3062 - val_accuracy: 0.8767\n",
      "Epoch 2/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.1935 - accuracy: 0.9260 - val_loss: 0.3308 - val_accuracy: 0.8728\n",
      "Epoch 3/42\n",
      "750/750 [==============================] - 51s 67ms/step - loss: 0.1081 - accuracy: 0.9621 - val_loss: 0.3876 - val_accuracy: 0.8582\n",
      "Epoch 4/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0684 - accuracy: 0.9770 - val_loss: 0.4960 - val_accuracy: 0.8535\n",
      "Epoch 5/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.5438 - val_accuracy: 0.8482\n",
      "Epoch 6/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.6060 - val_accuracy: 0.8492\n",
      "Epoch 7/42\n",
      "750/750 [==============================] - 51s 69ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.5243 - val_accuracy: 0.8363\n",
      "Epoch 8/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.6231 - val_accuracy: 0.8328\n",
      "Epoch 9/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 0.8282 - val_accuracy: 0.8428\n",
      "Epoch 10/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.7525 - val_accuracy: 0.8373\n",
      "Epoch 11/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 0.9893 - val_accuracy: 0.8323\n",
      "Epoch 12/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.7649 - val_accuracy: 0.8437\n",
      "Epoch 13/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.8697 - val_accuracy: 0.8398\n",
      "Epoch 14/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.9768 - val_accuracy: 0.8408\n",
      "Epoch 15/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 1.1309 - val_accuracy: 0.8405\n",
      "Epoch 16/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 1.1211 - val_accuracy: 0.8435\n",
      "Epoch 17/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 1.0153 - val_accuracy: 0.8445\n",
      "Epoch 18/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0096 - accuracy: 0.9962 - val_loss: 1.0332 - val_accuracy: 0.8340\n",
      "Epoch 19/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 1.0970 - val_accuracy: 0.8380\n",
      "Epoch 20/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 1.1613 - val_accuracy: 0.8378\n",
      "Epoch 21/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 1.1069 - val_accuracy: 0.8393\n",
      "Epoch 22/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 1.1092 - val_accuracy: 0.8377\n",
      "Epoch 23/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.0947 - val_accuracy: 0.8378\n",
      "Epoch 24/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 1.0086 - val_accuracy: 0.8402\n",
      "Epoch 25/42\n",
      "750/750 [==============================] - 52s 69ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 1.1807 - val_accuracy: 0.8352\n",
      "Epoch 26/42\n",
      "750/750 [==============================] - 51s 69ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 1.1699 - val_accuracy: 0.8373\n",
      "Epoch 27/42\n",
      "750/750 [==============================] - 51s 69ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 1.2379 - val_accuracy: 0.8297\n",
      "Epoch 28/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 1.1680 - val_accuracy: 0.8350\n",
      "Epoch 29/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 1.1741 - val_accuracy: 0.8402\n",
      "Epoch 30/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 1.2721 - val_accuracy: 0.8345\n",
      "Epoch 31/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.3056 - val_accuracy: 0.8357\n",
      "Epoch 32/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 1.2419 - val_accuracy: 0.8295\n",
      "Epoch 33/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 1.2103 - val_accuracy: 0.8305\n",
      "Epoch 34/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 1.2426 - val_accuracy: 0.8327\n",
      "Epoch 35/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.3313 - val_accuracy: 0.8358\n",
      "Epoch 36/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.3147 - val_accuracy: 0.8337\n",
      "Epoch 37/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 1.3638 - val_accuracy: 0.8307\n",
      "Epoch 38/42\n",
      "750/750 [==============================] - 50s 66ms/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 1.2788 - val_accuracy: 0.8400\n",
      "Epoch 39/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 1.3776 - val_accuracy: 0.8330\n",
      "Epoch 40/42\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.3275 - val_accuracy: 0.8370\n",
      "Epoch 41/42\n",
      "750/750 [==============================] - 51s 67ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 1.2520 - val_accuracy: 0.8412\n",
      "Epoch 42/42\n",
      "750/750 [==============================] - 51s 68ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 1.3217 - val_accuracy: 0.8333\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 1.3217 - accuracy: 0.8333\n",
      "Test Loss: 1.321691870689392\n",
      "Test Accuracy: 83.33333134651184\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=42, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model_json=model.to_json()\n",
    "with open(\"bangla-sequential-model.json\",\"w\")as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"bangla-sequential-model_wieghts.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
