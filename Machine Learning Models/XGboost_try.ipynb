{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"G:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\bengali_hate_v2.0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_from_sentence(sentence):\n",
    "    sentence_without_punctuation=\"\".join([c for c in sentence if c not in string.punctuation])\n",
    "    return sentence_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence without punctuation'] = df['sentence'].apply(lambda x:remove_punctuation_from_sentence(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnlp import BasicTokenizer\n",
    "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
    "from bnlp.corpus.util import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>category</th>\n",
       "      <th>hate</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>বৌদির দুধ দেকে তো আমার ই চোখ ঠিক ছিলো না - পোল...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>0</td>\n",
       "      <td>বৌদির দুধ দেকে তো আমার ই চোখ ঠিক ছিলো না  পোলা...</td>\n",
       "      <td>[বৌদির, দুধ, দেকে, তো, আমার, ই, চোখ, ঠিক, ছিলো...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>এই সরকার কে যারা নির্লজ্জের মত সাপোর্ট দিয়েছে ...</td>\n",
       "      <td>Political</td>\n",
       "      <td>1</td>\n",
       "      <td>এই সরকার কে যারা নির্লজ্জের মত সাপোর্ট দিয়েছে ...</td>\n",
       "      <td>[এই, সরকার, কে, যারা, নির্লজ্জের, মত, সাপোর্ট,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>পিলখানা হত্যাকান্ড বাংলাদেশের প্রতিরক্ষা ব্যবস...</td>\n",
       "      <td>Geopolitical</td>\n",
       "      <td>3</td>\n",
       "      <td>পিলখানা হত্যাকান্ড বাংলাদেশের প্রতিরক্ষা ব্যবস...</td>\n",
       "      <td>[পিলখানা, হত্যাকান্ড, বাংলাদেশের, প্রতিরক্ষা, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ভারতের অর্থনীতি নিয়ে আপনাদের ভাবতে হবে না। ভা...</td>\n",
       "      <td>Geopolitical</td>\n",
       "      <td>3</td>\n",
       "      <td>ভারতের অর্থনীতি নিয়ে আপনাদের ভাবতে হবে না। ভা...</td>\n",
       "      <td>[ভারতের, অর্থনীতি, নিয়ে, আপনাদের, ভাবতে, হবে,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>খানকির পুলা মালায়নদের মেরে সাফা করে ফেল</td>\n",
       "      <td>Personal</td>\n",
       "      <td>0</td>\n",
       "      <td>খানকির পুলা মালায়নদের মেরে সাফা করে ফেল</td>\n",
       "      <td>[খানকির, পুলা, মালায়নদের, মেরে, সাফা, করে, ফেল]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      category  hate  \\\n",
       "0  বৌদির দুধ দেকে তো আমার ই চোখ ঠিক ছিলো না - পোল...      Personal     0   \n",
       "1  এই সরকার কে যারা নির্লজ্জের মত সাপোর্ট দিয়েছে ...     Political     1   \n",
       "2  পিলখানা হত্যাকান্ড বাংলাদেশের প্রতিরক্ষা ব্যবস...  Geopolitical     3   \n",
       "3  ভারতের অর্থনীতি নিয়ে আপনাদের ভাবতে হবে না। ভা...  Geopolitical     3   \n",
       "4            খানকির পুলা মালায়নদের মেরে সাফা করে ফেল      Personal     0   \n",
       "\n",
       "                        sentence without punctuation  \\\n",
       "0  বৌদির দুধ দেকে তো আমার ই চোখ ঠিক ছিলো না  পোলা...   \n",
       "1  এই সরকার কে যারা নির্লজ্জের মত সাপোর্ট দিয়েছে ...   \n",
       "2  পিলখানা হত্যাকান্ড বাংলাদেশের প্রতিরক্ষা ব্যবস...   \n",
       "3  ভারতের অর্থনীতি নিয়ে আপনাদের ভাবতে হবে না। ভা...   \n",
       "4            খানকির পুলা মালায়নদের মেরে সাফা করে ফেল   \n",
       "\n",
       "                                  tokenized_sentence  \n",
       "0  [বৌদির, দুধ, দেকে, তো, আমার, ই, চোখ, ঠিক, ছিলো...  \n",
       "1  [এই, সরকার, কে, যারা, নির্লজ্জের, মত, সাপোর্ট,...  \n",
       "2  [পিলখানা, হত্যাকান্ড, বাংলাদেশের, প্রতিরক্ষা, ...  \n",
       "3  [ভারতের, অর্থনীতি, নিয়ে, আপনাদের, ভাবতে, হবে,...  \n",
       "4    [খানকির, পুলা, মালায়নদের, মেরে, সাফা, করে, ফেল]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_tokenizer = BasicTokenizer()\n",
    "df['tokenized_sentence'] = df['sentence without punctuation'].apply(lambda x: basic_tokenizer.tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Removed Stopped word'] = df['sentence without punctuation'].apply(lambda x: remove_stopwords(x,stopwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hate_speech']=df['Removed Stopped word'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['hate_speech']\n",
    "y=df['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = stopwords)\n",
    "cv.fit(x)\n",
    "\n",
    "# transform the training and testing data using count vectorizer object\n",
    "X_train_count =  cv.transform(X_train)\n",
    "X_test_count =  cv.transform(X_test)\n",
    "\n",
    "#Tfid transformer\n",
    "tfidf_tr = TfidfTransformer()\n",
    "X_train_count_tfidf = tfidf_tr.fit_transform(X_train_count)\n",
    "X_test_count_tfidf = tfidf_tr.transform(X_test_count)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tv_ngram = TfidfVectorizer(ngram_range=(1,2))\n",
    "tv_ngram.fit(x)\n",
    "X_train_tfidf_ngram =  tv_ngram.transform(X_train)\n",
    "X_test_tfidf_ngram =  tv_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierModel(classifier, Xtrain, Ytrain, Xtest,roc):\n",
    "    classifier.fit(Xtrain, Ytrain)\n",
    "    predictions = classifier.predict(Xtest)\n",
    "    print(30*'=')\n",
    "    print(f\"Accuracy : {accuracy_score(predictions, y_test)*float(100)}%\")\n",
    "    print(30*'=')\n",
    "    if roc:\n",
    "        probs = classifier.predict_proba(X_test_count_tfidf)\n",
    "        preds = probs[:,1]\n",
    "        fpr_svm, tpr_svm, threshold_svm = metrics.roc_curve(y_test, preds)\n",
    "        roc_auc_svm = metrics.auc(fpr_svm, tpr_svm)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.title(type(classifier).__name__)\n",
    "        plt.plot(fpr_svm, tpr_svm, 'b', label = 'AUC = %0.2f' % roc_auc_svm)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "    \n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBOOST with Count Vectors: \n",
      "==============================\n",
      "Accuracy : 69.03508771929825%\n",
      "==============================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\XGboost_try.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mXGBOOST with Count Vectors: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m classifierModel(XGBClassifier(), X_train_count, y_train, X_test_count,roc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mXGBOOST with Count Vectors + TF-IDF: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m classifierModel(XGBClassifier(), X_train_count_tfidf, y_train, X_test_count_tfidf,roc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\XGboost_try.ipynb Cell 14\u001b[0m in \u001b[0;36mclassifierModel\u001b[1;34m(classifier, Xtrain, Ytrain, Xtest, roc)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m probs \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict_proba(X_test_count_tfidf)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m preds \u001b[39m=\u001b[39m probs[:,\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m fpr_svm, tpr_svm, threshold_svm \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mroc_curve(y_test, preds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m roc_auc_svm \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mauc(fpr_svm, tpr_svm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/XGboost_try.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:962\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    874\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    875\u001b[0m ):\n\u001b[0;32m    876\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \n\u001b[0;32m    878\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m \n\u001b[0;32m    961\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    963\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:731\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    729\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m--> 731\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    733\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    734\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"\\nXGBOOST with Count Vectors: \")\n",
    "classifierModel(XGBClassifier(), X_train_count, y_train, X_test_count,roc=True)\n",
    "\n",
    "print(\"\\nXGBOOST with Count Vectors + TF-IDF: \")\n",
    "classifierModel(XGBClassifier(), X_train_count_tfidf, y_train, X_test_count_tfidf,roc=True)\n",
    "\n",
    "print(\"\\nXGBOOST with N-Gram Vectors: \")\n",
    "classifierModel(XGBClassifier(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
