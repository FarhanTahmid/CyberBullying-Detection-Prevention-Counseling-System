{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef53797",
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c6ece1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9979a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>চার নাস্তিক কুত্তার বাচ্চাদেরকে জুতা পেটা করতা...</td>\n",
       "      <td>1</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>দারুন গল্প</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19727</th>\n",
       "      <td>তাহসিনেশনের নকল পুরাদমে</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5491</th>\n",
       "      <td>ফরজের খবর নাই ছুন্নাত চোদায় ভন্ড মাদার চোদ</td>\n",
       "      <td>1</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29175</th>\n",
       "      <td>সালমানের চার বাগের এক ঘাওহবে না এখন কার নায়ক ক...</td>\n",
       "      <td>0</td>\n",
       "      <td>Meme, TikTok and others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13768</th>\n",
       "      <td>নাটকটা অনেক ভাল লাগলো</td>\n",
       "      <td>0</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17601</th>\n",
       "      <td>পুলিশের কাজে বাঁধা দেওয়ার কারণে এদেরকে জরিমানা...</td>\n",
       "      <td>0</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>আসসালামু আলাইকুম কেমন আছেন সিলেট হবিগঞ্জ থেকে ...</td>\n",
       "      <td>0</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8017</th>\n",
       "      <td>খাংকির পোলা মোনাজাত ধর</td>\n",
       "      <td>1</td>\n",
       "      <td>celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>এরকম কুত্তার বাচ্চা মোল্লা গুলো যেখানে সেখানে ...</td>\n",
       "      <td>1</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  hate  \\\n",
       "6446   চার নাস্তিক কুত্তার বাচ্চাদেরকে জুতা পেটা করতা...     1   \n",
       "13521                                         দারুন গল্প     0   \n",
       "19727                            তাহসিনেশনের নকল পুরাদমে     0   \n",
       "5491          ফরজের খবর নাই ছুন্নাত চোদায় ভন্ড মাদার চোদ     1   \n",
       "29175  সালমানের চার বাগের এক ঘাওহবে না এখন কার নায়ক ক...     0   \n",
       "...                                                  ...   ...   \n",
       "13768                              নাটকটা অনেক ভাল লাগলো     0   \n",
       "17601  পুলিশের কাজে বাঁধা দেওয়ার কারণে এদেরকে জরিমানা...     0   \n",
       "20285  আসসালামু আলাইকুম কেমন আছেন সিলেট হবিগঞ্জ থেকে ...     0   \n",
       "8017                              খাংকির পোলা মোনাজাত ধর     1   \n",
       "6711   এরকম কুত্তার বাচ্চা মোল্লা গুলো যেখানে সেখানে ...     1   \n",
       "\n",
       "                      category  \n",
       "6446                  religion  \n",
       "13521            entertainment  \n",
       "19727                 religion  \n",
       "5491                  religion  \n",
       "29175  Meme, TikTok and others  \n",
       "...                        ...  \n",
       "13768            entertainment  \n",
       "17601                    crime  \n",
       "20285                 religion  \n",
       "8017                 celebrity  \n",
       "6711                  religion  \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\Bengali hate speech.csv\")\n",
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7a26dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbca045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad6885b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_from_sentence(sentence):\n",
    "    sentence_without_punctuation=\"\".join([c for c in sentence if c not in string.punctuation])\n",
    "    return sentence_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac04ecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                        sentence without punctuation  \n",
       "0                          যত্তসব পাপন শালার ফাজলামী  \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার  \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...  \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়  \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence without punctuation'] = df['sentence'].apply(lambda x:remove_punctuation_from_sentence(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd702a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnlp import BasicTokenizer\n",
    "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
    "from bnlp.corpus.util import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3077b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডা...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                        sentence without punctuation  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                  tokenized_sentence  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]  \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডা...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_tokenizer = BasicTokenizer()\n",
    "df['tokenized_sentence'] = df['sentence without punctuation'].apply(lambda x: basic_tokenizer.tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53bf82f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>hate</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence without punctuation</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>Removed Stopped word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>যত্তসব পাপন শালার ফাজলামী</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "      <td>[যত্তসব, পাপন, শালার, ফাজলামী]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>পাপন শালা রে রিমান্ডে নেওয়া দরকার</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]</td>\n",
       "      <td>[পাপন, শালা, রে, রিমান্ডে, দরকার]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "      <td>[জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>শালা লুচ্চা দেখতে পাঠার মত দেখা যায়</td>\n",
       "      <td>[শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]</td>\n",
       "      <td>[শালা, লুচ্চা, পাঠার, মত, যায়]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব</td>\n",
       "      <td>[তুই, তো, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডা...</td>\n",
       "      <td>[তুই, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডায়, খ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  hate category  \\\n",
       "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports   \n",
       "\n",
       "                        sentence without punctuation  \\\n",
       "0                          যত্তসব পাপন শালার ফাজলামী   \n",
       "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
       "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
       "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
       "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব   \n",
       "\n",
       "                                  tokenized_sentence  \\\n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]   \n",
       "1           [পাপন, শালা, রে, রিমান্ডে, নেওয়া, দরকার]   \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...   \n",
       "3        [শালা, লুচ্চা, দেখতে, পাঠার, মত, দেখা, যায়]   \n",
       "4  [তুই, তো, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডা...   \n",
       "\n",
       "                                Removed Stopped word  \n",
       "0                     [যত্তসব, পাপন, শালার, ফাজলামী]  \n",
       "1                  [পাপন, শালা, রে, রিমান্ডে, দরকার]  \n",
       "2  [জিল্লুর, রহমান, স্যারের, ছেলে, এতো, বড়, জারজ,...  \n",
       "3                     [শালা, লুচ্চা, পাঠার, মত, যায়]  \n",
       "4  [তুই, শালা, গাজা, খাইছচ, ।, তুর, মার, হেডায়, খ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Removed Stopped word'] = df['sentence without punctuation'].apply(lambda x: remove_stopwords(x,stopwords))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5202979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hate_speech']=df['Removed Stopped word'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a641ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['hate_speech']\n",
    "y=df['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7bb4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca151002",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = stopwords)\n",
    "cv.fit(x)\n",
    "\n",
    "# transform the training and testing data using count vectorizer object\n",
    "X_train_count =  cv.transform(X_train)\n",
    "X_test_count =  cv.transform(X_test)\n",
    "\n",
    "#Tfid transformer\n",
    "tfidf_tr = TfidfTransformer()\n",
    "X_train_count_tfidf = tfidf_tr.fit_transform(X_train_count)\n",
    "X_test_count_tfidf = tfidf_tr.transform(X_test_count)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tv_ngram = TfidfVectorizer(ngram_range=(1,2))\n",
    "tv_ngram.fit(x)\n",
    "X_train_tfidf_ngram =  tv_ngram.transform(X_train)\n",
    "X_test_tfidf_ngram =  tv_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa6940fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierModel(classifier, Xtrain, Ytrain, Xtest,roc):\n",
    "    classifier.fit(Xtrain, Ytrain)\n",
    "    predictions = classifier.predict(Xtest)\n",
    "    print(30*'=')\n",
    "    print(f\"Accuracy : {accuracy_score(predictions, y_test)*float(100)}%\")\n",
    "    print(30*'=')\n",
    "    if roc:\n",
    "        probs = classifier.predict_proba(X_test_count_tfidf)\n",
    "        preds = probs[:,1]\n",
    "        fpr_svm, tpr_svm, threshold_svm = metrics.roc_curve(y_test, preds)\n",
    "        roc_auc_svm = metrics.auc(fpr_svm, tpr_svm)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.title(type(classifier).__name__)\n",
    "        plt.plot(fpr_svm, tpr_svm, 'b', label = 'AUC = %0.2f' % roc_auc_svm)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "    \n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd68cdc9",
   "metadata": {},
   "source": [
    "LINEAR SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48ea2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinearSVM with Count Vectors: \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLinearSVM with Count Vectors: \")\n",
    "classifierModel(SVC(kernel='linear', probability=True), X_train_count, y_train, X_test_count,roc=True)\n",
    "\n",
    "print(\"\\nLinearSVM with Count Vectors + TF-IDF: \")\n",
    "classifierModel(SVC(kernel='linear', probability=True), X_train_count_tfidf, y_train, X_test_count_tfidf,roc=True)\n",
    "\n",
    "print(\"\\nLinearSVM with N-Gram Vectors: \")\n",
    "classifierModel(SVC(kernel='linear', probability=True), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "598a7bd7",
   "metadata": {},
   "source": [
    "NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNaive Bayes with Count Vectors: \")\n",
    "classifierModel(MultinomialNB(), X_train_count, y_train, X_test_count,roc=True)\n",
    "\n",
    "print(\"\\nNaive Bayes with Count Vectors + TF-IDF: \")\n",
    "classifierModel(MultinomialNB(), X_train_count_tfidf, y_train, X_test_count_tfidf,roc=True)\n",
    "\n",
    "print(\"\\nNaive Bayes with N-Gram Vectors: \")\n",
    "classifierModel(MultinomialNB(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a853eecd",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced43645",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\linear_svm_try.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifierModel(RandomForestClassifier(random_state\u001b[39m=\u001b[39mrstate,n_estimators\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m), X_train_count, y_train, X_test_count,roc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRandom Forrest Classifier with Count Vectors + TF-IDF: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m classifierModel(RandomForestClassifier(random_state\u001b[39m=\u001b[39;49mrstate,n_estimators\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m), X_train_count_tfidf, y_train, X_test_count_tfidf,roc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRandom Forrest Classifier with N-Gram Vectors: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m classifierModel(RandomForestClassifier(random_state\u001b[39m=\u001b[39mrstate,n_estimators\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mg:\\OneDrive - northsouth.edu\\CODES\\PROJECTS\\PROJECT-CSE299-CYBERBULLYING PREVENTION-DETECTION and MENTAL COUNSELING SYSTEM\\Machine Learning Models\\linear_svm_try.ipynb Cell 21\u001b[0m in \u001b[0;36mclassifierModel\u001b[1;34m(classifier, Xtrain, Ytrain, Xtest, roc)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassifierModel\u001b[39m(classifier, Xtrain, Ytrain, Xtest,roc):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     classifier\u001b[39m.\u001b[39;49mfit(Xtrain, Ytrain)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(Xtest)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20northsouth.edu/CODES/PROJECTS/PROJECT-CSE299-CYBERBULLYING%20PREVENTION-DETECTION%20and%20MENTAL%20COUNSELING%20SYSTEM/Machine%20Learning%20Models/linear_svm_try.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m30\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    454\u001b[0m )(\n\u001b[0;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    456\u001b[0m         t,\n\u001b[0;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    458\u001b[0m         X,\n\u001b[0;32m    459\u001b[0m         y,\n\u001b[0;32m    460\u001b[0m         sample_weight,\n\u001b[0;32m    461\u001b[0m         i,\n\u001b[0;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    938\u001b[0m         X,\n\u001b[0;32m    939\u001b[0m         y,\n\u001b[0;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\farha\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nRandom Forrest Classifier with Count Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=rstate,n_estimators=512), X_train_count, y_train, X_test_count,roc=True)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with Count Vectors + TF-IDF: \")\n",
    "classifierModel(RandomForestClassifier(random_state=rstate,n_estimators=512), X_train_count_tfidf, y_train, X_test_count_tfidf,roc=True)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with N-Gram Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=rstate,n_estimators=512), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05e8451d",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLogistic Regression with Count Vectors: \")\n",
    "classifierModel(LogisticRegression(), X_train_count, y_train, X_test_count,roc=True)\n",
    "\n",
    "print(\"\\nLogistic Regression with Count Vectors + TF-IDF: \")\n",
    "classifierModel(LogisticRegression(), X_train_count_tfidf, y_train, X_test_count_tfidf,roc=True)\n",
    "\n",
    "print(\"\\nLogistic Regression with N-Gram Vectors: \")\n",
    "classifierModel(LogisticRegression(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram,roc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42823f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
